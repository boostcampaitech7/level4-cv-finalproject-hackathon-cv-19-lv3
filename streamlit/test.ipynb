{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_found': True, 'audio_found': False, 'metadata': {}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [360, 640], 'bitrate': None, 'fps': 33.33, 'codec_name': 'gif', 'profile': None}], 'input_number': 0}], 'duration': 12.27, 'bitrate': 41894, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'gif', 'video_profile': None, 'video_size': [360, 640], 'video_bitrate': None, 'video_fps': 33.33, 'video_duration': 12.27, 'video_n_frames': 408}\n",
      "/mnt/d/naver_boostcamp/project/level4-cv-finalproject-hackathon-cv-19-lv3/.venv/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux64-v4.2.2 -i hong.gif -loglevel error -f image2pipe -vf scale=360:640 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "MoviePy - Building video hong_test.mp4.\n",
      "MoviePy - Writing video hong_test.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready hong_test.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy import VideoFileClip\n",
    "\n",
    "VideoFileClip('hong.gif').write_videofile('hong_test.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# video generation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Initializing mediapipe pose class.\n",
    "mp_pose = mp.solutions.pose\n",
    "# Setting up the Pose model for images.\n",
    "pose_img = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.5, model_complexity=1)\n",
    "# Setting up the Pose model for videos.\n",
    "pose_video = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, \n",
    "                          min_tracking_confidence=0.5, model_complexity=1)\n",
    "\n",
    "# Initializing mediapipe drawing class to draw landmarks on specified image.\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "def estimPose_img(input_file, pose=pose_img, landmarks_c=(234,63,247), connection_c=(117,249,77), \n",
    "                   thickness=20, circle_r=10, display=True):\n",
    "    \n",
    "    # Read the input image\n",
    "    if isinstance(input_file, str) :\n",
    "        input_img = cv2.imread(input_file)\n",
    "    else :\n",
    "        input_img = input_file\n",
    "    \n",
    "    # Create a copy of the input image\n",
    "    output_img = input_img.copy()\n",
    "    \n",
    "    # Perform the Pose Detection.\n",
    "    results = pose.process(output_img) # 이거 이렇게 하면 트래킹은 안되자나..\n",
    "    \n",
    "    # Retrieve the height and width of the input image.\n",
    "    height, width, _ = input_img.shape\n",
    "    \n",
    "    # Initialize a list to store the detected landmarks.\n",
    "    landmarks = []\n",
    "    \n",
    "    # Check if any landmarks are detected.\n",
    "    if results.pose_landmarks:\n",
    "        skeleton = np.zeros_like(input_img)\n",
    "        mp_drawing.draw_landmarks(skeleton, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(landmarks_c, thickness, circle_r),\n",
    "                                  mp_drawing.DrawingSpec(connection_c, thickness, circle_r))\n",
    "    \n",
    "        # Draw Pose landmarks on the output image.\n",
    "        mp_drawing.draw_landmarks(output_img, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(landmarks_c, thickness, circle_r),\n",
    "                                  mp_drawing.DrawingSpec(connection_c, thickness, circle_r))\n",
    "        \n",
    "        # Iterate over the detected landmarks.\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            landmarks.append((int(landmark.x * width), int(landmark.y * height),\n",
    "                                  (landmark.z * width)))\n",
    "            \n",
    "    # print(results.pose_landmarks)\n",
    "    # Check if we want to display.\n",
    "    if display:\n",
    "        # Display the original input image and the resulting image.\n",
    "        plt.figure(figsize=[15,15])\n",
    "        plt.subplot(121);plt.imshow(input_img[:,:,::-1]);plt.title(\"Original image\");plt.axis('off');\n",
    "        plt.subplot(122);plt.imshow(output_img[:,:,::-1]);plt.title(\"Output image\");plt.axis('off');\n",
    "        \n",
    "        # Plot the Pose landmarks in 3D.\n",
    "        mp_drawing.plot_landmarks(results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "    # Just get output_img and landmarks\n",
    "    else:\n",
    "        # Return the output image and the found landmarks.\n",
    "        return output_img, skeleton, landmarks\n",
    "\n",
    "def estimPose_video(input_file, pose_video=pose_video, landmarks_c=(234,63,247), connection_c=(117,249,77), \n",
    "                 thickness=1, circle_r=1, nrows_frames=4, ncols_frames=3):\n",
    "    \n",
    "    # Initialize the VideoCapture object to read from a video stored in the disk.\n",
    "    video = cv2.VideoCapture(input_file)\n",
    "    \n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frames = []\n",
    "    original_video_frames = []\n",
    "    only_skeleton_frames = []\n",
    "    \n",
    "    for i in range(total_frames):\n",
    "        # Read a frame.\n",
    "        ok, frame = video.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        original_video_frames.append(frame.copy())\n",
    "    \n",
    "        # Check if frame is not read properly.\n",
    "        if not ok:\n",
    "            # Break the loop.\n",
    "            break\n",
    "        \n",
    "        # Get the width and height of the frame\n",
    "        frame_height, frame_width, _ =  frame.shape\n",
    "        # Resize the frame while keeping the aspect ratio.\n",
    "        frame = cv2.resize(frame, (int(frame_width * (640 / frame_height)), 640))\n",
    "        frame, skeleton, _ = estimPose_img(frame, pose_video, landmarks_c, connection_c, thickness, \n",
    "                              circle_r, display=False)\n",
    "        frames.append(frame)\n",
    "        only_skeleton_frames.append(skeleton)\n",
    "    return original_video_frames, only_skeleton_frames, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1736942567.248719  195429 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1736942567.249511  195422 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1736942567.291276  195433 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1736942567.291588  195422 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1736942567.541296  195433 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    }
   ],
   "source": [
    "original_video_frames, only_skeleton_frames, frames = estimPose_video(\"hong.mp4\", thickness=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W, C = frames[0].shape\n",
    "fps = 30\n",
    "out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (W, H))\n",
    "\n",
    "for frame in frames:\n",
    "    out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (360, 640) to (368, 640) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "[swscaler @ 0x34b6bbc0] Warning: data is not aligned! This can lead to a speed loss\n"
     ]
    }
   ],
   "source": [
    "import imageio.v3 as iio\n",
    "\n",
    "output_path = \"test.mp4\"\n",
    "iio.imwrite(output_path, frames, fps=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
